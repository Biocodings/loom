import hashlib
import json

from django.db import models
from django.core.exceptions import ValidationError

from .helpers import ValidationHelper
from .helpers import DataObjectTypeHelper


class _Hashable(models.Model):

    # A hashable has data stored in JSON format, and a unique id created
    # as a hash of that JSON

    _json = models.TextField(blank=False, null=False, validators=[ValidationHelper.validate_and_parse_json])
    _id = models.TextField(primary_key=True, blank=False, null=False)

    def save(self):
        self._json = self._clean_json(self._json)
        self._calculate_and_set_unique_id()
        self.full_clean() #This runs validators
        super(_Hashable, self).save()

    def get_id(self):
        return self._id

    def _get_json(self):
        # This is _private to encourage use of get_data_as_* methods
        # which can properly integrate data with metadata and
        # expand child objects.
        return self._json

    @classmethod
    def get_by_id(cls, id):
        return cls.objects.get(_id=id)

    @classmethod
    def _clean_json(cls, data_json):
        # Validate json, remove whitespace, and sort keys
        data_obj = ValidationHelper.validate_and_parse_json(data_json)
        return json.dumps(data_obj, sort_keys=True)

    def _calculate_unique_id(self):
        data_json = self._json
        return hashlib.sha256(data_json).hexdigest()

    def _calculate_and_set_unique_id(self):
        self._id = self._calculate_unique_id()

    def _validate_unique_id(self):
        if self._id != self._calculate_unique_id():
            raise ValidationError('Content hash %s does not match the contents %s', (self._id, self.get_unique_id))

    def clean(self):
        # This method validates the model as a whole, and is called by full_clean when the object is saved.
        # If children override this, they should call it as super(ChildClass, self).clean()
        self._validate_unique_id()


class _BaseModelData(_Hashable):

    # This stores the "data" part of a model, but not the "metadata"
    # It is separate because it can be shared by more than one model,
    # but as far as analysis is concerned metadata has on effect and
    # results from any models with identical data are equivalent.

    @classmethod
    def create(cls, raw_data_json):
        o = cls(_json=raw_data_json)
        o.save()
        return o

    def clean(self):
        if 'metadata' in json.loads(self._get_json()):
            raise ValidationError('metadata cannot be saved to _BaseModelData object')
        super(_BaseModelData, self).clean()


class _BaseModel(_Hashable):

    # All models consist of data and metadata. Both are JSON-formatted strings. 
    # In the JSON used to construct a model, metadata is designated with the 'metadata' key. 
    # data is everything else.
    # All models have a unique ID generated by hashing a JSON-formatted serialization of the model.
    # metadata can only contain data which does not affect analysis results. metadata is not made
    # available at runtime. Examples of metadata are coordinates for visual layout in a block diagram editor,
    # comments, human-readable software name and version number, or credits to authors of the pipeline components.
    #
    # When an object is linked to another, it includes metadata. When judging whether an analysis has been run,
    # however, metadata is ignored. For this reason, data is recorded as a separate object in the data store with 
    # its own unique ID. Many objects with different metadata may link to the same data, and when analysis as run 
    # any results produced by those objects are considered interchangeable.

    @classmethod
    def _create_model_from_json(cls, raw_data_json):
        raw_data_obj = ValidationHelper.validate_and_parse_json(raw_data_json)
        metadata_obj = cls._strip_metadata_from_obj(raw_data_obj)
        data_model = _BaseModelData.create(json.dumps(raw_data_obj, sort_keys=True))
        new_obj = {
            "data": {
                "id": data_model.get_id()
            },
        }
        if metadata_obj is not None:
            new_obj["metadata"] = metadata_obj
        o = cls(_json=json.dumps(new_obj, sort_keys=True))
        o.save()
        return o

    @classmethod
    def _strip_metadata_from_obj(cls, data_obj):
        try:
            metadata = data_obj.pop('metadata')
        except KeyError:
            metadata = None
        return metadata

    def get_data_id(self):
        return json.loads(self._get_json())['data']['id']

    def get_data_as_obj(self, metadata=True, shallow=False):
        data_id = self.get_data_id()
        data_model = _BaseModelData.get_by_id(data_id)
        data_obj = json.loads(data_model._get_json())
        if metadata:
            if self.get_metadata_as_obj() is not None:
                data_obj['metadata'] = self.get_metadata_as_obj()
        if not shallow:
            self._expand_children(data_obj, metadata=True)
        return data_obj

    def _expand_children(self, data_obj, metadata):
        # Converts children from object id's to 
        # expanded objects loaded from the database.

        # Subclasses with children need to define 'child_classes',
        # which should be a dict of keys and the corresponding class.
        if not hasattr(self, 'child_classes'):
            # Nothing to expand
            return

        # Looping over possible children of this object
        for key in self.child_classes.keys():
            # Proceed if that class of children is defined in this object
            if data_obj.get(key) is not None:
                if not isinstance(data_obj.get(key), list):
                    # Expect a singleton dict
                    child_id = data_obj.get(key)['id']
                    # setting shallow=True ensures that children are recursively expanded
                    expanded_children = self.child_classes[key].get_by_id(child_id).get_data_as_obj(metadata=metadata, shallow=True)
                    data_obj[key] = expanded_children
                else:
                    # Expect a list
                    expanded_children = []
                    for child in data_obj.get(key):
                        child_id = child['id']
                        # setting shallow=True ensures that children are recursively expanded
                        expanded_children.append(self.child_classes[key].get_by_id(child_id).get_data_as_obj(metadata=metadata, shallow=True))
                    data_obj[key] = expanded_children

    def get_data_as_json(self, metadata=True, shallow=False):
        data_obj = self.get_data_as_obj(metadata=metadata, shallow=shallow)
        return json.dumps(data_obj, sort_keys=True)

    def get_metadata_as_obj(self):
        model_obj = json.loads(self._get_json())
        return model_obj.get('metadata')

    def get_metadata_as_json(self):
        return json.dumps(self.get_metadata_as_obj())

    def clean(self):
        for key in json.loads(self._get_json()):
            if key not in ['metadata', 'data']:
                raise ValidationError('"%s" is not a valid key for _BaseModel' % key)
        super(_BaseModel, self).clean()

class Application(_BaseModel):

    APPLICATION_TYPES = ['docker', 'local']
    # Docker applications load 1 or more docker containers.
    # Local applications modify environment variables to place
    # executables on the path.

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))

    @classmethod
    def _clean_and_parse_data(cls, data_json):
        data_obj = ValidationHelper.validate_and_parse_json(data_json)
        application_type = cls._clean_application_type(data_obj)
        if application_type == 'docker':
            cls._clean_docker_application_data(data_obj)
        elif application_type == 'local':
            cls._clean_local_application_data(data_obj)
        else:
            raise Exception()
        return data_obj

    @classmethod
    def _clean_application_type(cls, data_obj):
        application_type = ValidationHelper.validate_key(data_obj, 'application_type', [str, unicode])
        ValidationHelper.validate_in(application_type, cls.APPLICATION_TYPES)
        return application_type

    @classmethod
    def _clean_docker_application_data(cls, data_obj):
        raise ValidationError("TODO. Docker applications have not been implemented.")

    @classmethod
    def _clean_local_application_data(cls, data_obj):
        ValidationHelper.validate_keys(data_obj, required=['application_type'], optional=['paths', 'metadata'])


class Environment(_BaseModel):

    # Environment holds information needed to configure the runtime environment
    # for a specific task. The same information should be able to make an
    # application available in any environment where the task will run.
    #
    # Although we may abuse this feature in development to store information about 
    # a manually configured local environment, that is not how Environment should
    # be used in production.

    child_classes = {
        'applications': Application
    }

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        applications_obj = data_obj.get('applications')
        application_ids = []
        if applications_obj is not None:
            for application in applications_obj:
                a = Application.create(json.dumps(application, sort_keys=True))
                application_ids.append({"id": a.get_id()})
        data_obj['applications'] = application_ids        
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))
    
    @classmethod
    def _clean_and_parse_data(cls, raw_data_json):
        data_obj = ValidationHelper.validate_and_parse_json(raw_data_json)
        ValidationHelper.validate_keys(data_obj, required=None, optional=['applications', 'metadata'])
        ValidationHelper.validate_object_class(data_obj.get('applications'), list)
        return data_obj

    def get_applications(self):
        data = self.get_data_as_obj()
        return data.get('applications')


class _AbstractDataObject(_BaseModel):
    pass


class Port(_AbstractDataObject):

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))

    @classmethod
    def _clean_and_parse_data(cls, data):
        data_obj = ValidationHelper.validate_and_parse_json(data)
        ValidationHelper.validate_keys(data_obj, required=['name', 'data_type'], optional='metadata')
        DataObjectTypeHelper.validate_data_type(data_obj['data_type'], value=None)
        return data_obj

    def get_data_type(self):
        data = self.get_data_as_obj()
        return data.get('data_type')

    def get_name(self):
        data = self.get_data_as_obj()
        return data.get('name')

class Binding(_BaseModel):

    # A Binding connects the output Port of one Analysis
    # To the input Port of another Analysis
    #
    # It should be contained by an analysis, but that information
    # is saved in the parent Analysis, not the Binding.

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))

    @classmethod
    def _clean_and_parse_data(cls, data):
        data_obj = ValidationHelper.validate_and_parse_json(data)
        ValidationHelper.validate_keys(data_obj, required=['source_analysis', 'source_port_name', 'destination_analysis', 'destination_port_name'], optional='metadata')
        return data_obj

    def get_source_analysis(self):
        data = self.get_data_as_obj()
        return data.get('source_analysis')

    def get_source_port_name(self):
        data = self.get_data_as_obj()
        return data.get('source_port_name')

    def get_destination_analysis(self):
        data = self.get_data_as_obj()
        return data.get('destination_analysis')

    def get_destination_port_name(self):
        data = self.get_data_as_obj()
        return data.get('destination_port_name')


class ParentChildBinding(_BaseModel):

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))

    @classmethod
    def _clean_and_parse_data(cls, data):
        data_obj = ValidationHelper.validate_and_parse_json(data)
        ValidationHelper.validate_keys(data_obj, required=['child_analysis', 'child_port_name', 'parent_port_name'], optional='metadata')
        return data_obj

    def get_child_analysis(self):
        data = self.get_data_as_obj()
        return data.get('source_analysis')

    def get_child_port_name(self):
        data = self.get_data_as_obj()
        return data.get('child_port_name')

    def get_parent_port_name(self):
        data = self.get_data_as_obj()
        return data.get('parent_port_name')


class _AbstractAnalysis(_BaseModel):

    pass


class Task(_AbstractAnalysis):

    VALID_INTERPRETERS = ['python', 'bash']

    child_classes = { 'inputports': Port,
                      'outputports': Port,
                      'environment': Environment
    }

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)

        inputports_obj = data_obj.get('inputports')
        inputport_ids = []
        if inputports_obj is not None:
            for port in inputports_obj:
                a = Port.create(json.dumps(port, sort_keys=True))
                inputport_ids.append({"id": a.get_id()})
        data_obj['inputports'] = inputport_ids

        outputports_obj = data_obj.get('outputports')
        outputport_ids = []
        if outputports_obj is not None:
            for port in outputports_obj:
                a = Port.create(json.dumps(port, sort_keys=True))
                outputport_ids.append({"id": a.get_id()})
        data_obj['outputports'] = outputport_ids

        environment_obj = data_obj.get('environment')
        if environment_obj is not None:
            a = Environment.create(json.dumps(environment_obj, sort_keys=True))
            data_obj['environment'] = {"id": a.get_id()}

        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))
    
    @classmethod
    def _clean_and_parse_data(cls, raw_data_json):
        data_obj = ValidationHelper.validate_and_parse_json(raw_data_json)
        ValidationHelper.validate_keys(data_obj, required=['script', 'interpreter'], 
                                       optional=['metadata', 'inputports', 'outputports', 'environment'])
        ValidationHelper.validate_object_class(data_obj.get('outputports'), list)
        ValidationHelper.validate_object_class(data_obj.get('inputports'), list)
        ValidationHelper.validate_object_class(data_obj.get('script'), [unicode, str])
        ValidationHelper.validate_in(data_obj.get('interpreter'), cls.VALID_INTERPRETERS)
        return data_obj

    def get_environment(self):
        data = self.get_data_as_obj()
        return data.get('environment')

    def get_inputports(self):
        data = self.get_data_as_obj()
        return data.get('inputports')

    def get_outputports(self):
        data = self.get_data_as_obj()
        return data.get('outputports')

    def get_interpreter(self):
        data = self.get_data_as_obj()
        return data.get('interpreter')

    def get_script(self):
        data = self.get_data_as_obj()
        return data.get('script')

"""
class Analysis(_AbstractAnalysis):
    # ports
#    child_analyses = models.ManyToManyField(_AbstractAnalysis)
    # bindings
    # parentchildbindings
#    ports = models.ManyToManyField('Port')

    class Meta:
        verbose_name_plural = "analyses"

class DataImport(_AbstractDataObject):
    import_note = models.TextField()
"""

class DataObject(_AbstractDataObject):

#    source = models.ForeignKey(_AbstractDataObject)

    @classmethod
    def create(cls, raw_data_json):
        data_obj = cls._clean_and_parse_data(raw_data_json)
        return cls._create_model_from_json(json.dumps(data_obj, sort_keys=True))

    @classmethod
    def _clean_and_parse_data(cls, data):
        data_obj = ValidationHelper.validate_and_parse_json(data)
        ValidationHelper.validate_keys(data_obj, required=['data_type', 'value'], optional='metadata')
        DataObjectTypeHelper.validate_data_type(data_obj['data_type'], data_obj['value'])
        return data_obj

    def get_data_type(self):
        data = self.get_data_as_obj()
        return data['data_type']

    def get_value(self):
        data = self.get_data_as_obj()
        return data['value']
